---
title: "Project: Salm"
author: "AÃ«la Jagot"
date: "15 avril 2024"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

Breslow (1984) analyses some mutagenicity assay data (shown below) on salmonella in which
three plates have been processed at each dose i of quinoline and the number of revertant
colonies of TA98 Salmonella measured. A certain dose-response curve is suggested by theory.
The data are shown below:

```{r}
Ndoses <- 6                                          # Number of doses
Nplates <- 3                                         # Number of plates
y <- structure(c(15, 16, 16, 27, 33, 20, 21, 18, 26, # Number of revertant colonies measured
                 41, 38, 27, 29, 21, 33, 60, 41, 42), .Dim = c(6, 3))
x <- c(0, 10, 33, 100, 333, 1000)                    # Dose of quinoline (in \mu g per plate)
```


This is assumed to be a random effects Poisson model allowing for over-dispersion. 
Let $x_i$ be the dose on the plates $i_1$, $i_2$ and $i_3$. Then we assume
$$y_{ij} \sim \text{Poisson}(\mu_{ij})$$
$$\log(\mu_{ij}) = \alpha + \beta \log(x_i + 10) + \gamma x_i +\lambda_{ij}$$
$$\lambda_{ij} \sim \text{Normal}(0, \tau)$$
$\alpha , \beta , \gamma , \tau$ are given independent "noninformative" priors.

We carry out the calculations necessary for building the model. We remember that Ndose = 6 and Nplates = 3.

$\underline{For \; \alpha}:$

We have a non-informative prior distribution for $\alpha$ :
$$\alpha \sim \text{Normal}(0,\sigma_\alpha^2) \quad \text{with} \; \sigma_{\alpha} \; \text{known}.$$
We want to calculate the posterior distribution for $\alpha$:
$$\pi(\alpha|\cdots) \propto \pi(\alpha) \prod_{i=1}^{6} \prod_{j=1}^{3} \pi(y_{ij}|\alpha,\beta,\gamma, \lambda_{ij}) \propto e^{\frac{-1}{2}\frac{\alpha^2}{\sigma_\alpha^2}} \prod_{i=1}^{6} \prod_{j=1}^{3} \mu_{ij}^{y_{ij}}e^{-\mu_{ij}}$$
We don't recognize the distribution. It is possible to do a Metropolis-Hastings algorithm. We switch to logarithm.
$$\log(\pi(\alpha| \cdots)) \propto \frac{-\alpha^2}{2\sigma_{\alpha}^2} + \sum_{i=1}^6 \sum_{j=1}^3 (y_{ij}\log(\mu_{ij})-\mu_{ij})$$

$\underline{For \; \beta \; and \; \gamma}:$

We obtain the same results than with $\alpha$:
$$\log(\pi(\beta| \cdots)) \propto \frac{-\beta^2}{2\sigma_{\beta}^2} + \sum_{i=1}^6 \sum_{j=1}^3 (y_{ij}\log(\mu_{ij})-\mu_{ij})$$
$$\log(\pi(\gamma| \cdots)) \propto \frac{-\gamma^2}{\sigma_{2\gamma}^2} + \sum_{i=1}^6 \sum_{j=1}^3 (y_{ij}\log(\mu_{ij})-\mu_{ij})$$

$\underline{For \; \tau}:$

We have a non-informative prior distribution for $\tau$ :
$$\tau\sim \text{Gamma}(\xi,\phi) \quad \text{with} \; \xi \; and \; \phi \; \text{known}.$$
We know that $\tau = \frac{1}{\sigma^2}$.
$$\pi(\tau|\cdots) \propto \pi(\tau) \prod_{i=1}^{6} \prod_{j=1}^{3} \pi(\lambda_{ij}|\tau) \propto \tau^{\xi-1}e^{-\phi \tau} \prod_{i=1}^{6} \prod_{j=1}^{3} \sqrt{\tau} e^{\frac{-1}{2}\tau\lambda_{ij}^2} \propto \tau^{\xi + 18 - 1} e^{-\tau(\beta + \frac{1}{2} \sum_{i=1}^{6} \sum_{j=1}^{3} \lambda_{ij}^2)}$$
We recognize a Gamma distribution. We obtain that:
$$\tau \sim Gamma(\xi + 18,\beta + \frac{1}{2} \sum_{i=1}^{6} \sum_{j=1}^{3} \lambda_{ij}^2)$$

These are the initialization states for the model:

```{r}
alpha <- 0
beta <- 0
gamma <- 0
tau <- 0.1
lambda <-structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 
                   .Dim = c(6, 3))
```

We implement the model:

```{r}
model <- function(Ndoses, Nplates, x, y, alpha, beta, gamma, tau, lambda, 
                  nchain, prop_sd){
  ## Hyperparameters
  alpha.sigma2 <- .000001
  beta.sigma2 <- .000001
  gamma.sigma2 <- .000001
  tau.xi <- .001
  tau.phi <- .001
  ## Initialization
  mu <- matrix(NA, nrow = Ndoses, ncol = Nplates)
  mu.candidate <- matrix(NA, nrow = Ndoses, ncol = Nplates)
  chain <- matrix(NA, nrow = nchain + 1, ncol = 4)
  colnames(chain) <- c("alpha", "beta", "gamma", "tau")
  chain[1,] <- c(alpha, beta, gamma, tau)
  ## Update
  for(k in 1:nchain){
    tau.rate <- tau.xi + Ndoses*Nplates
    tau.shape <- 1/tau.phi + .5*sum(lambda**2)
    tau <- rgamma(n = 1, rate = tau.rate, shape = tau.shape)
    chain[k + 1, 4] <- tau
    lambda <- structure(rnorm(n = Nplates * Ndoses, mean = 0, sd = sqrt(chain[k + 1, 4])), .Dim = c(Ndoses, Nplates))
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu[j, i] <- exp(chain[k, 1] + chain[k, 2] * log(x[j] + 10) + chain[k, 3] * x[j] + lambda[j, i])
      }
    }
    # Metropolis-Hastings for alpha
    alpha.candidate <- rnorm(1, mean = chain[k, 1], sd = prop_sd[1])
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu.candidate[j, i] <- exp(alpha.candidate + chain[k, 2] * log(x[j] + 10) + chain[k, 3] * x[j] + lambda[j, i])
      }
    }
    alpha.top <- alpha.candidate^2 / (-2*alpha.sigma2) + sum(y * log(mu.candidate) - mu.candidate)
    alpha.bottom <- - chain[k, 1]^2 / (-2*alpha.sigma2) + sum(y * log(mu) - mu)
    alpha.ratio <- alpha.top - alpha.bottom
    if(!is.na(alpha.ratio) && log(runif(1)) < alpha.ratio){
      chain[k + 1, 1] <- alpha.candidate
    } else {
      chain[k + 1, 1] <- chain[k, 1]
    }
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu[j, i] <- exp(chain[k+1, 1] + chain[k, 2] * log(x[j] + 10) + chain[k, 3] * x[j] + lambda[j, i])
      }
    }
    # Metropolis-Hastings for beta
    beta.candidate <- rnorm(1, mean = chain[k, 2], sd = prop_sd[2])
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu.candidate[j, i] <- exp(chain[k+1,1] + beta.candidate * log(x[j] + 10) + chain[k, 3] * x[j] + lambda[j, i])
      }
    }
    beta.top <- beta.candidate^2 / (-2*beta.sigma2) + sum(y * log(mu.candidate) - mu.candidate)
    beta.bottom <- chain[k, 2]^2 / (-2*beta.sigma2) + sum(y * log(mu) - mu)
    beta.ratio <- beta.top - beta.bottom
    if(!is.na(beta.ratio) && log(runif(1)) < beta.ratio){
      chain[k + 1, 2] <- beta.candidate
    } else {
      chain[k + 1, 2] <- chain[k, 2]
    }
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu[j, i] <- exp(chain[k+1, 1] + chain[k+1, 2] * log(x[j] + 10) + chain[k, 3] * x[j] + lambda[j, i])
      }
    }
    # Metropolis-Hastings for gamma
    gamma.candidate <- rnorm(1, mean = chain[k, 3], sd = prop_sd[3])
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu.candidate[j, i] <- exp(chain[k+1, 1] + chain[k+1, 2] * log(x[j] + 10) + gamma.candidate * x[j] + lambda[j, i])
      }
    }
    gamma.top <- gamma.candidate^2 / (-2*gamma.sigma2) + sum(y * log(mu.candidate) - mu.candidate)
    gamma.bottom <- chain[k, 3]^2 / (-2*gamma.sigma2) + sum(y * log(mu) - mu)
    gamma.ratio <- gamma.top - gamma.bottom
    if(!is.na(gamma.ratio) && log(runif(1)) < gamma.ratio){
      chain[k + 1, 3] <- gamma.candidate
    } else {
      chain[k + 1, 3] <- chain[k, 3]
    }
    for(j in 1:Ndoses){
      for(i in 1:Nplates){
        mu[j, i] <- exp(chain[k+1, 1] + chain[k+1, 2] * log(x[j] + 10) + chain[k+1, 3] * x[j] + lambda[j, i])
      }
    }
  }
  vec <- 1/chain[,4]
  chain.new <- cbind(chain[,1:3],vec)
  colnames(chain.new) <- c("alpha", "beta", "gamma", "sigma")
  return(chain.new)
}
```

```{r}
nchain <- 5000
prop_sd <-  c(1,1,1)
chain <- model(Ndoses, Nplates, x, y, alpha, beta, gamma, tau, lambda, nchain, prop_sd)
```

```{r}
library(coda)
chain.new <- chain[1001:5000,]
plot(mcmc(chain.new[,1]))
plot(mcmc(chain.new[,2]))
plot(mcmc(chain.new[,3]))
plot(mcmc(chain.new[,4]))
```

```{r} 
chain <- chain[1001:4001,]
res = data.frame(
  mean = round(apply(chain, 2, mean), 4),
  sd = round(apply(chain, 2, sd), 4)
)
print(res)
```



